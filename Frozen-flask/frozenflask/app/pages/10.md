title:
date:
tags:
sidebar:


最近在学习网络爬虫，


###什么是爬虫？

网络爬虫，顾名思义就是在网上爬来爬去的“虫子”，它能够按照一定规则自动抓取网络数据的脚本。比如说你找到了一个特别棒的网站，上面全是妹子图。而你想把它们存到你的随身硬盘当中。如果你要一张一张保存的话那需要比较持久的耐力，这个时候你就需要通过爬虫来帮你抓取你心心念念的妹子图。

那么如何通过爬虫来完成任务呢？

###运行机制

其实爬虫的工作流程和人是一样的，都需要经过下面几个步骤：
	
> 使用本机的IP连接到网络 ->使用地址登入网站 ->看到网页内容 ->筛选需要的信息 -> 保存下载 -> 登入新网页 ->重复之前的动作

是不是非常相似？

###为什么使用python

很多编程语言都可以写爬虫，可我们为什么选择python呢？总的来说就是四个字：**简单够用**：

- Python语法简单，开发效率高
- Python 有着丰富第三方爬虫工具库(requests,scrapy,BeautifulSoup)
- 爬虫的速度瓶颈大多是在网络阻塞上，非超大规模爬取很少遇到计算性能瓶颈
- Python起初被用来开发搜索引擎，所以关于爬虫的资料很多，社区活跃

###工具准备

- Python3 
- urllib.request
	熟悉python2的对urllib库一定不陌生，我们要用的是其中的urlopen方法
- re(正则表达式)
	正则表达式是根据一定规则来匹配相应字符串








